{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Customized Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have ever wanted to build a model using deep learning, you have encountered the big question of how many layers I should use? or what should be the size of this layers?\n",
    "\n",
    "Using `tensorlfow` or even `keras` sequential model makes it harded to simply add one or multiple layer. You need to modify a the code before each run or you need to write different blocks of code for models with various number of layers. However, `keras` functional api makes it easy to use a for loop and add as many layers as you like in few lines of code. Using this feature, I constructed five classes of deep architecture startin from a simple dense fully-connected deep network to a complex hybrid convolutional autoencoder. \n",
    "\n",
    "The classes are initiated given the number of nodes in each layer or the type of each layer and then they build the desired model and makes them ready for you to train and test.\n",
    "\n",
    "For simplicity, other parameters like activation functions, optimizer, loss, etc. are hard-coded. I chose them based on what is usually used in a similar network. But if you like, you can add them to you class init params and even play with those as well. I used `adam` optimizer for all of the classes and `categorical_crossentropy` and `mse` for losses. I also add a dropout layer right after the input layer and after the encoded layer if there's any. The default value of the `dropout` is 0.0001 and mainly I used it for simplicity in my coding and for loop.\n",
    "\n",
    "First, I go over each class and give and example of the usage of it. \n",
    "At last, I will bring and example of training few DNNs with different number of nodes and layers to compare them when training a classifier for MNIST digit dataset.\n",
    "\n",
    "If you are not familiar with neural networks and you don't any knowledge on the topic please use google and learn the basic concept before you dive into this library :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Deep Neural Networks\n",
    "A Deep Neural Network is built of an input layer, a bunch of hidden layers and and output layers which can be the result of classification or in some cases the result of regression (note that each case should use it's specific loss function)\n",
    "\n",
    "Below is a simple illustration of a DNN:\n",
    "\n",
    "![DNN](figures/DNN.png \"DNN\")\n",
    "\n",
    "The class I designed is used for classification with relu actication function for all the hidden layers and sigmoid for the final output layer. You can initiate your model by giving a list of integers which contain the number of nodes in each layer including your input and output layers! Yeah! It's just that easy to make any simple deep network.\n",
    "\n",
    "Let's say your input has 784 feature(this is actually the number of pixels in MNIST digit data which are 28x28 images), you have 10 classes (cause there are 10 digits), and you want to have a layer with 256 nodes right after the input and another layer with 32 nodes after that. Just look at the example below and follow it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_networks import DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_neural_network\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 209,514\n",
      "Trainable params: 209,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model = DNN(layer_size=[784, 256, 32, 10])\n",
    "dnn_model.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Autoencoders\n",
    "\n",
    "Autoencoders are mostly use when you don't have label for your data. The purpose is to shrink your giant input to a more abstract representation. The model is train in a way that the encoded input carries enough information so that it can reconstruct the original input as close as possible. \n",
    "\n",
    "Below is a simple illustration of an AE :\n",
    "\n",
    "![AE](figures/AE.png \"AE\")\n",
    "\n",
    "The autoencoder I designed, uses relu activation function for all layers. For building your desired autoencoder, you just need to input a list of integers containing the number of nodes in each layer from the input layer to the encoded input layer (the middle part) the class will automatically mirror this setting for the decoder part. \n",
    "\n",
    "Let's say you want to create an autoencoder to shrink your MNIST data into 32 features. And you want to have another hidden layer in between of the input and encoded space with 256 nodes. So you entire autoencoder will have the following number of nodes in this order: 784, 256, 32, 256, 784. You just need to provide a list containing [784, 256, 32] just like the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_networks import AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 784)               201488    \n",
      "=================================================================\n",
      "Total params: 419,120\n",
      "Trainable params: 419,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                8224      \n",
      "=================================================================\n",
      "Total params: 209,184\n",
      "Trainable params: 209,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model = AE(encoder_layer_size=[784, 256, 32])\n",
    "dnn_model.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class provides two models: \n",
    "1. Autoencoder: which gives you the reconstructed input\n",
    "2. Encoder: which provides the encoded features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hybrid Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"hybrid_neural_network\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 784)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 784)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          200960      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           8224        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          8448        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 10)           330         flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 784)          201488      dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 419,450\n",
      "Trainable params: 419,450\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                8224      \n",
      "=================================================================\n",
      "Total params: 209,184\n",
      "Trainable params: 209,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from neural_networks import HNN\n",
    "\n",
    "dnn_model = HNN(encoder_layer_size=[784, 256, 32], num_classes=10)\n",
    "dnn_model.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 28, 64)            17984     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 14, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 14, 16)            10256     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                3616      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 32,186\n",
      "Trainable params: 32,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from neural_networks import CNN\n",
    "\n",
    "cae_model = CNN(input_dim=[28,28], layers='cmcmd' , layers_param=[64,2,16,2,32,10])\n",
    "cae_model.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"hybrid_convolutional_autoencoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 28, 28)       0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 28, 64)       17984       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 14, 64)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 14, 16)       10256       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 7, 16)        0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 112)          0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 32)           3616        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 112)          3696        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 7, 16)        0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 7, 2)         322         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d (UpSampling1D)    (None, 112, 2)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 112, 2)       42          up_sampling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, 7168, 2)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 10)           330         flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 28, 28)       399924      up_sampling1d_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 436,170\n",
      "Trainable params: 436,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"convolutional_encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 28, 64)            17984     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 14, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 14, 16)            10256     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                3616      \n",
      "=================================================================\n",
      "Total params: 31,856\n",
      "Trainable params: 31,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from neural_networks import CAE\n",
    "\n",
    "cae_model = CAE(input_dim=[28,28], layers='cmcmdcucu' , layers_param=[64,2,16,2,32,2,16,2,64], num_classes=10)\n",
    "cae_model.print_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
